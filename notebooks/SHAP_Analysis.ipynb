{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç SHAP Analysis: AQI Prediction Model Explainability\n",
    "\n",
    "**Purpose:** Understand which features drive our AQI predictions using SHAP (SHapley Additive exPlanations)\n",
    "\n",
    "**Model:** Random Forest Multi-Output Regressor (predicts 24h, 48h, 72h)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Install SHAP if not available\n",
    "try:\n",
    "    import shap\n",
    "    print(f\"‚úÖ SHAP version: {shap.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Installing SHAP...\")\n",
    "    !pip install shap\n",
    "    import shap\n",
    "\n",
    "# Enable SHAP's JS visualizations in notebook\n",
    "shap.initjs()\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Trained Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained multi-output model\n",
    "model_path = \"../models/best_model_multi_output_24h_48h_72h.pkl\"\n",
    "\n",
    "with open(model_path, 'rb') as f:\n",
    "    model_data = pickle.load(f)\n",
    "\n",
    "model = model_data['model']\n",
    "feature_names = model_data['feature_names']\n",
    "model_name = model_data.get('model_name', 'Unknown')\n",
    "metrics = model_data.get('metrics', {})\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {model_name}\")\n",
    "print(f\"üìä Features: {len(feature_names)}\")\n",
    "print(f\"üéØ Model Type: Multi-Output (24h, 48h, 72h)\")\n",
    "print(f\"\")\n",
    "print(f\"üìà Model Performance:\")\n",
    "print(f\"   Average RMSE: {metrics.get('rmse', 'N/A'):.2f}\")\n",
    "print(f\"   Average R¬≤: {metrics.get('r2', 'N/A'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature data from MongoDB\n",
    "from src.database import Database\n",
    "\n",
    "db = Database()\n",
    "features = db.get_features()\n",
    "df = pd.DataFrame(features)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df)} feature records from MongoDB\")\n",
    "\n",
    "# Prepare X with only the features used by the model\n",
    "available_features = [f for f in feature_names if f in df.columns]\n",
    "X = df[available_features].dropna()\n",
    "\n",
    "print(f\"üìä Using {len(available_features)} features for SHAP analysis\")\n",
    "print(f\"üìä Samples: {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance (Built-in Random Forest)\n",
    "\n",
    "Random Forest has built-in feature importance based on how much each feature reduces impurity across all trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest\n",
    "# For multi-output, we average importance across all outputs\n",
    "\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# Create importance DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': available_features,\n",
    "    'Importance': importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Display top 15 features\n",
    "print(\"\\nüèÜ Top 15 Most Important Features:\")\n",
    "print(\"=\" * 40)\n",
    "for i, row in importance_df.head(15).iterrows():\n",
    "    bar = \"‚ñà\" * int(row['Importance'] * 100)\n",
    "    print(f\"{row['Feature']:<25} {row['Importance']:.4f} {bar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Feature Importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "top_n = 15\n",
    "top_features = importance_df.head(top_n)\n",
    "\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, top_n))[::-1]\n",
    "\n",
    "plt.barh(range(top_n), top_features['Importance'], color=colors)\n",
    "plt.yticks(range(top_n), top_features['Feature'])\n",
    "plt.xlabel('Feature Importance (Mean Decrease in Impurity)')\n",
    "plt.title('Top 15 Feature Importance - Random Forest Multi-Output Model', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_charts/1_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Chart saved: shap_charts/1_feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SHAP Analysis (for 24h Prediction)\n",
    "\n",
    "SHAP values show how each feature contributes to individual predictions.\n",
    "\n",
    "For multi-output, we'll analyze the 24h prediction (first output) as our primary horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SHAP explainer for Random Forest\n",
    "# We'll use a sample of data for efficiency\n",
    "\n",
    "# Sample 100 data points for SHAP calculation (faster)\n",
    "sample_size = min(100, len(X))\n",
    "X_sample = X.sample(n=sample_size, random_state=42)\n",
    "\n",
    "print(f\"üîç Computing SHAP values for {sample_size} samples...\")\n",
    "print(\"   (This may take a minute)\")\n",
    "\n",
    "# Create TreeExplainer (efficient for Random Forest)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "print(\"‚úÖ SHAP values calculated!\")\n",
    "print(f\"   Shape: {len(shap_values)} outputs √ó {shap_values[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Summary Plot for 24h Prediction (first output)\n",
    "print(\"\\nüìä SHAP Summary Plot - 24h Prediction\")\n",
    "print(\"   Each dot = one prediction\")\n",
    "print(\"   Color = feature value (red=high, blue=low)\")\n",
    "print(\"   X-axis = impact on prediction\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values[0], X_sample, feature_names=available_features, show=False)\n",
    "plt.title('SHAP Summary Plot - 24h AQI Prediction', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_charts/2_shap_summary_24h.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Chart saved: shap_charts/2_shap_summary_24h.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Bar Plot - Mean Absolute Impact\n",
    "print(\"\\nüìä SHAP Feature Importance (Mean |SHAP|)\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values[0], X_sample, feature_names=available_features, plot_type=\"bar\", show=False)\n",
    "plt.title('Mean |SHAP| Values - Feature Importance for 24h Prediction', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_charts/3_shap_importance_bar.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Chart saved: shap_charts/3_shap_importance_bar.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Single Prediction Explanation (Waterfall Plot)\n",
    "\n",
    "Let's explain ONE specific prediction to show how each feature pushed the prediction higher or lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain a single prediction\n",
    "sample_idx = 0  # First sample\n",
    "\n",
    "print(f\"\\nüîç Explaining prediction for sample {sample_idx}:\")\n",
    "print(f\"   Actual features: (first 5 shown)\")\n",
    "for feat in available_features[:5]:\n",
    "    print(f\"   - {feat}: {X_sample.iloc[sample_idx][feat]:.2f}\")\n",
    "\n",
    "# Get prediction\n",
    "pred = model.predict(X_sample.iloc[[sample_idx]])[0]\n",
    "print(f\"\\n   Prediction: 24h={pred[0]:.1f}, 48h={pred[1]:.1f}, 72h={pred[2]:.1f} PM2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall plot for single prediction\n",
    "print(\"\\nüìä Waterfall Plot - How features affect this prediction\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.plots.waterfall(shap.Explanation(\n",
    "    values=shap_values[0][sample_idx],\n",
    "    base_values=explainer.expected_value[0],\n",
    "    data=X_sample.iloc[sample_idx],\n",
    "    feature_names=available_features\n",
    "), show=False)\n",
    "plt.title(f'Waterfall Plot - Explaining 24h Prediction (Sample {sample_idx})', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_charts/4_waterfall_explanation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Chart saved: shap_charts/4_waterfall_explanation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Dependence Plot\n",
    "\n",
    "Shows how the most important feature affects predictions across all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top feature\n",
    "top_feature = importance_df.iloc[0]['Feature']\n",
    "print(f\"\\nüìä Dependence Plot for top feature: {top_feature}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.dependence_plot(\n",
    "    top_feature, \n",
    "    shap_values[0], \n",
    "    X_sample,\n",
    "    feature_names=available_features,\n",
    "    show=False\n",
    ")\n",
    "plt.title(f'SHAP Dependence Plot: {top_feature}', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_charts/5_dependence_plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Chart saved: shap_charts/5_dependence_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multi-Output Comparison\n",
    "\n",
    "Compare feature importance across all three prediction horizons (24h, 48h, 72h)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare SHAP importance across horizons\n",
    "horizon_names = ['24h', '48h', '72h']\n",
    "\n",
    "# Calculate mean |SHAP| for each horizon\n",
    "importance_by_horizon = {}\n",
    "for i, horizon in enumerate(horizon_names):\n",
    "    mean_shap = np.abs(shap_values[i]).mean(axis=0)\n",
    "    importance_by_horizon[horizon] = mean_shap\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(importance_by_horizon, index=available_features)\n",
    "comparison_df['Average'] = comparison_df.mean(axis=1)\n",
    "comparison_df = comparison_df.sort_values('Average', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nüìä Top 10 Features Importance by Horizon:\")\n",
    "print(comparison_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(x - width, comparison_df['24h'], width, label='24h', color='#2ecc71')\n",
    "bars2 = ax.bar(x, comparison_df['48h'], width, label='48h', color='#3498db')\n",
    "bars3 = ax.bar(x + width, comparison_df['72h'], width, label='72h', color='#e74c3c')\n",
    "\n",
    "ax.set_ylabel('Mean |SHAP| Value')\n",
    "ax.set_title('Feature Importance Comparison Across Prediction Horizons', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison_df.index, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_charts/6_horizon_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Chart saved: shap_charts/6_horizon_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ KEY INSIGHTS FROM SHAP ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Top 5 features\n",
    "top5 = importance_df.head(5)\n",
    "print(\"\\nüìä Top 5 Most Important Features:\")\n",
    "for i, (_, row) in enumerate(top5.iterrows(), 1):\n",
    "    print(f\"   {i}. {row['Feature']} ({row['Importance']*100:.1f}%)\")\n",
    "\n",
    "# Weather features importance\n",
    "weather_features = ['temp', 'humidity', 'pressure', 'wind_speed', 'clouds']\n",
    "weather_importance = importance_df[importance_df['Feature'].isin(weather_features)]['Importance'].sum()\n",
    "print(f\"\\nüå§Ô∏è Weather Features Total Importance: {weather_importance*100:.1f}%\")\n",
    "\n",
    "# Lag/Rolling features importance\n",
    "temporal_features = [f for f in available_features if 'lag' in f or 'rolling' in f]\n",
    "temporal_importance = importance_df[importance_df['Feature'].isin(temporal_features)]['Importance'].sum()\n",
    "print(f\"‚è∞ Temporal Features (Lag/Rolling) Importance: {temporal_importance*100:.1f}%\")\n",
    "\n",
    "# Pollutant features importance\n",
    "pollutant_features = ['pm2_5', 'pm10', 'no2', 'o3', 'co', 'so2']\n",
    "pollutant_importance = importance_df[importance_df['Feature'].isin(pollutant_features)]['Importance'].sum()\n",
    "print(f\"üè≠ Pollutant Features Importance: {pollutant_importance*100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ SHAP Analysis Complete!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÅ Generated Charts\n",
    "\n",
    "| Chart | Description |\n",
    "|-------|-------------|\n",
    "| `1_feature_importance.png` | Random Forest built-in feature importance |\n",
    "| `2_shap_summary_24h.png` | SHAP summary plot for 24h prediction |\n",
    "| `3_shap_importance_bar.png` | Mean |SHAP| values as bar chart |\n",
    "| `4_waterfall_explanation.png` | Single prediction breakdown |\n",
    "| `5_dependence_plot.png` | Top feature's effect on predictions |\n",
    "| `6_horizon_comparison.png` | Feature importance across 24h/48h/72h |\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusion:** This analysis shows which features most strongly influence our AQI predictions, helping us understand and trust the model's decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
